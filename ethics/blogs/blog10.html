<html>
	<head>
		<title>
			Reading 06: Privacy
		</title>
	</head><body>
		<h1>
			Reading 06: Privacy
		</h1>Sun, February 25, 2018<p><br />
In my opinion, technology companies should not purposely weaken encryption of implement backdoors in their products for the purpose of government surveillance.  I think that if we started to take that approach, then it would be contrary to the human dignity that everyone deserves, especially in the case of the world today, where opting out of technology is not a viable possibility.  <br />
<br />
I do not think that it is the responsibility of Apple to provent violenet or harmful activities that their platforms enable.  Apple already does more than they need to for preventing harmful activities.  The iPhone ecosystem is incredibly locked down because Apple has a huge number of rules and regulations about what can be on a the App Store, and they have zero official methods of installing apps from anywhere else on the device (but this isn’t the time for me to get upset about that).  The thing that an iPhone does that the government wanted them to open up for them is allow communication.  In the New York times article about the San Bernadino incident, the author says that "Apple argues that the software the F.B.I. wants it to create does not exist. But technologists say the company can do it".  I think this sounds ridiculous if you look at it in the lens of traditional American business.  The government does not own Apple.  It is not Apple's responsibility to write software that the government wants.  Apple created a device for people to buy, and what people do with that is up to Apple, not the government.  If the government wants to come up with their own phones with backdoors for people to buy, or outlaw iPhones, I would love to see them try.   <br />
<br />
In a world of both extreme terrorism and free flowing communication, the way to battle the terrorism is not to stop the communication.  Even if that theoretically would work, which I do not believe, I think that there are other ways that we could work on countering terrorism that do not restrict the freedom of the members of our global society.  <br />
<br />
My response to the question about national security and whether or not saving lives or protecting the nation is worth less individual privacy is simple – I think that the concerns for privacy are stronger than those of national security.  The Ars Technica article about American Spies tells us that "Ars readers may remember the National Security Agency’s LOVEINT scandal, in which intelligence staffers used the agency’s vast spy infrastructure to target their ex-partners. As far as we are aware, no one knows what punishments, if any, were doled out to those NSA staffers." Does this really sound like an issue of national security?  More to the point, does this kind of thing make me want to trust a random government agent with my own private matters?  Do I want to trust anyone other than myself with my private matters?  The freedom to choose who we trust is present when we are communicating in person.  Why is that different now that we are communicating over text on our devices.  How about this scenario: Assume the US Government is 100% unbiased, fair, and responsible. The government requires Apple to put a backdoor in iPhones.  They do so.  What exactly is making it so that only the US government has the ability to use this backdoor.  Nothing lasts forever.  Security that twenty years ago would have been considered quite strong is probably currently breakable by some teenager who found hashcat on an internet forum and decided to try and break it.  Do we really trust that what Apple comes up with for the government is completely unbreakable by those of all other nations?  In the article about Microsoft suing the US Government over disallowing notification of users when the government requested their emails, the author said "Redmond, Washington-based Microsoft drew support in the case from tech leaders including Apple Inc., Google and Amazon.com Inc., which argued the very future of mobile and cloud computing is at stake if customers can’t trust that their data will remain private. They said the federal law allowing the searches goes “far beyond any necessary limits” and infringes users’ fundamental rights."  For many users, it is bad enough that Google and Amazon get access to so much of our private information, and in those cases, we had to agree to their terms and services.  The government should care about the people and make progress to combat our national issues that do not put us in a state of subservience to people at government agencies we did not choose and will never know about.  (I was going to add a comment here about gun control but decided it wasn’t the place).  <br />
<br />
I do not like the argument "if you have nothing to hide, then you have nothing to fear".  Just because I am doing nothing wrong does not mean that I am doing something I want to be public.  If you told someone you wanted to put a camera in their room to record them all day and that it was going to be seen by someone they don’t know but that one day maybe if they wanted to hurt someone, it might stop them?  It is an affront to basic human dignity and sounds like you are making the assumption that everyone is someday likely to be a criminal.  Jeremy Bentham describes the idea of a Panopticon, a structure with a bunch of rooms surrounding one central room.  From that central room, one can watch those in the surrounding rooms, but from those rooms you cannot tell if you are being watched or not.  The person in the center cannot watch all other people at once, but because those people do not know if they are watched, they behave all the time.  This sounds a lot like what those in favor of surveillance want.  The only thing is, in his letter, Bentham describes the Panopticon as a prison.   <br />
</p>
	</body>
</html>