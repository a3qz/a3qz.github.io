<html>
	<head>
		<title>
			Reading 05: With great power comes great responsibility 
		</title>
	</head><body>
		<h1>
			Reading 05: With great power comes great responsibility 
		</h1>Sun, February 18, 2018<p><br />
From the readings, what were the root causes of the Therac-25 accidents? What are the challenges for software developers working safety-critical systems, how should they approach these projects, and should they be held liable when accidents happen?<br />
<br />
According to "Investigation of the Therac-25 Accidents -- Part IV", there are four key contributing factors to the Therac-25 accidents.  The first of these is "management inadequacies and lack of procedures for following through on all reported incidents".  The second is "overconfidence in the software and removal of hardware interlocks (making the software into a single point of failure that could lead to an accident)", the third is "presumably less-than-acceptable software-engineering practices", and the fourth is "unrealistic risk assessments along with overconfidence in the results of these assessments".  The first is clearly a problem because of the way that the errors were presented - these machines were setting themselves up to deliver a lethal dose of radiation, and their only error was a single number that was poorly documented error code that you could push past with a single keystroke.  The second is a little bit harder to argue, as it was understandable that the designers thought it wise to trust their software and try to save costs by not implementing expensive hardware.  That being said, when developing something that literally blasts radiation into people, maybe it is best to be safe rather than sorry.  This reminds me of a quote attributed to Alan Shepard: ""When reporters asked Shepard what he thought about as he sat atop the Redstone rocket, waiting for liftoff, he had replied, 'The fact that every part of this ship was built by the lowest bidder.'".  Cost is everything in our society.  The third point, that the software engineering practices in place were not appropriate, is definitely true.  In "Killed by a Machine: The Therac-25", it says that the code was written by a single individual.  For something this mission critical, that seems a bit ridiculous that there was not at least another set of eyes on the code. Finally, the overconfident risk assessments point is hard to argue with as well.  In theory, those making the machine should have been the experts.  Yes, they were probably blinded and it would have been better if they could get an independent group to evaluate the machine, but I don’t think it is unreasonable that people should have trusted their estimates.  <br />
<br />
Software engineers working on safety-critical systems have to deal with the burden of ensuring awareness of potential error.  Though all software engineering projects should be taken incredibly seriously and be well tested, when safety is a concern, even more care needs to be taken.  Computers can have a tendency to act unpredictably even when we know the machine should be consistent.  When it comes to safety, that is not acceptable.  Every possible variation needs to be tested for and accounted for, and any risks need to be communicated accurately to any and all users.  <br />
<br />
I think that the question of accountability is very difficult to answer.  There are definitely times when the software engineer is to be held accountable, but I think that there are also times when thye are not.  It all has to do with how much information has been communicated to the engineer by others involved in the project.  If the engineer knows of the risks involved, and still participates in bad engineering practices, then I think that they are slightly at fault.  However, if the engineer is not informed of level of risk and importance of the software to safety, then I don’t think it would be fair to place the blame on the engineer.  I really don’t think that it is possible to give a blanket answer to who is liable when accidents happen.  In the real world any piece of software and hardware has so many different hands on it and so many different factors that I am not sure it would be possible to really figure out where liability lies except in very specific cases.  <br />
</p>
	</body>
</html>