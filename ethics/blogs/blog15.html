<html>
	<head>
		<title>
			Reading 11: Intelligence  
		</title>
	</head><body>
		<h1>
			Reading 11: Intelligence  
		</h1>Sat, April 8, 2018<p><br />
Prior to doing the readings, I would define artificial intelligence as a computer program designed to perform tasks as intelligently (or more intelligently) than a human can.  The first article, titled "What is artificial intelligence?", answers that question by defining it as a sub category of computer science with the goal "to enable the development of computers that are able to do things normally done by people -- in particular, things associated with people acting intelligently".  This is relatively reflective of my definition.  It is different from human intelligence in that it is purposely designed and can be a lot more focused.  An AI has the option of being "narrow", e.g. focused specifically on solving one specific problem.  Though "general" AI does exist that does not have such a specific goal, humans do not have the option to be not general.  <br />
I think that these examples are definitely more than just interesting tricks and gimmicks.  I would disagree with the IEEE article "Why AlphaGo is not AI".  The author of that seems to have a very specific idea of what AI is, which I think is unfairly strict.  I would argue that these programs are amazing insights in the potential of AI.  For the most part, their focus is on relatively inconsequential examples such as games.  However, I believe, as do many, that this "could lead to lots of really useful applications in medical research, industry, environmental preservation, and many other areas" (also from the IEEE article).  We have tested in these the safe environments of games, and now we can expand it out to fields where we might be able to even save lives with AI.  <br />
I do not think that the Turing Test is a valid measure of intelligence.  I think that you can nitpick about the implementation quite a bit and make a solid argument; however, at the core, I don’t think that a computer that could win the imitation game would necessarily be considered intelligent per se.  I would tend to agree with the Chinese Room theory.  I think that it is entirely possible to simulate intelligence blindly following a series of instructions or conditionals without having any sort of actual understanding of the content, which I would say is a prerequisite of intelligence.  <br />
<br />
I do not think that the concerns about artificial intelligence are warranted.  I am not particularly concerned with the dangers.  The biggest concern that was addressed was, as put by the Washington Post: “An ultra-intelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind".  I do not think that this is really the case.  I think that the role of man and machine will continually change as time goes on.  However, I do not see a potential case where man is just rendered completely irrelevant.  The technologies that are being developed today are for the use in aiding man or freeing up his labor in areas where he is held back.  Machines for their own sake have no real value, they only exist to aid man in his efforts.  <br />
I think that my answer to if a computing system could ever be considered a mind should be taken with a grain of salt because I do not have a ton of knowledge about the workings of the human mind.  I do not think that humans are just biological computers.  I think that there are way more factors and characteristics of biological material and processes that are just not existent in any computers.  We do not have a full understanding of the human body.  Maybe in the future, this will not be the case, and we could be found to be entirely deterministic.  I just do not see that as reality with my knowledge of the world.  I do however think that it would be possible for a computing system to have morality.  It is possible to have a system of morality with a set of fixed rules.  However, I would not consider the morality the machines own, rather, I would say that it is the morality that it was given thanks to the engineers and designers that worked on it, and potentially also its users.   I think that the ethical implications of that are that we should take the actions of machines and their users seriously morally, because technology is not free from moral responsibility.  <br />
</p>
	</body>
</html>