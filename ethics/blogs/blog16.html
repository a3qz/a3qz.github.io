<html>
	<head>
		<title>
			Reading 12: Cars  
		</title>
	</head><body>
		<h1>
			Reading 12: Cars  
		</h1>Sat, April 14, 2018<p><br />
The abstract of the article "The social dilemma of autonomous vehicles" very plainly states that "Autonomous vehicles (AVs) should reduce traffic accidents".  That is, from my understanding, the biggest motivation and argument for them.  In the US currently, an average of 102 people die to a car crash every day (https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812451).  Driving is essential to the life of the average American, so making it safer is a big motivator.  There exist other arguments, like the increased productivity of those with long commutes, but that is really small in comparison.  The two biggest arguments against it are that the self-driving cars will actually be less safe than humans due to the difficulty of the task that is driving, and that it takes away the autonomy of making life and death decisions from the person in the vehicle to the engineer that designed it.  I do think that if we got the technology to the point where it could handle the wide variety of conditions that exist on roads, then it would be safer.  <br />
<br />
The article in question hits the nail on the head in my opinion.  "The utilitarian course of action, in that situation, would be for the AV to swerve and kill its passenger, but AVs programmed to follow this course of action might discourage buyers who believe their own safety should trump other considerations."  This quote shows all of the possible risk.  I think that there are consumers that would not want a vehicle that would ever risk its owner.  I think that I more or less agree with the utilitarian approach to this kind of situation.  I do think a potentially beneficial addition, if possible, would be for the vehicle to determine who is in the wrong legally, when choosing a course of action.  I think the one who is liable is the one who caused the situation to occur.  In the case that it was the car, it is the responsibility of both the owner and the company.  <br />
<br />
I believe that the economic impact is not going to be substantial, and definitely will be long not short term.  I think that the social impact will mostly impact those whose identity is tied to their vehicle.  As someone from a place where probably half of the people I know have parents who work in the auto industry, there is a lot of emphasis on the car as an extension of your personality.  However, for lots of people, their car is just how they get from one place to another.  Those people will have less social impact.  I think that the government role in regulating self-driving cars should be consistent with how they regulate regular motor vehicles.  <br />
<br />
I think that I would like a car with self-driving as an option, and with a range of toggles on the different self-driving features.  When I am going on a drive like my ride to ND, which is 4 hours of constant farmland other than the first and last 20 minutes, I would love to be able to tune out and stop driving.  However, there are times when driving can be a pleasant activity, and it is nice to be able to be in control and not just along for the ride.   I donâ€™t want it to "just work", I want to have the options to choose how much control I have over my vehicle.  <br />
</p>
	</body>
</html>